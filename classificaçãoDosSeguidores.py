import pandas as pd
import logging
import os
import re
from datetime import datetime

# --- CONFIGURA√á√ïES GERAIS ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Nome do arquivo CSV de entrada (gerado pelo script de coleta de dados avan√ßados)
ARQUIVO_ENTRADA = "leads_detalhados.csv" 

# Nome do arquivo CSV final que ser√° gerado com TODAS as an√°lises
ARQUIVO_SAIDA = "perfis_analise_completa.csv"

# ======================= CONFIGURA√á√ïES PARA AN√ÅLISE =======================
# Voc√™ pode personalizar estas listas para refinar a precis√£o da an√°lise

# Palavras-chave para buscar na bio
PALAVRAS_CHAVE_BIO_GERAL = [
    'agendamento', 'whatsapp', 'delivery', 'promo√ß√£o', 'desconto',
    'online', 'link na bio', 'contato', 'or√ßamento', 'hor√°rio',
    'envio', 'pedidos', 'retirada', 'loja', 'frete gr√°tis',
    'novidades', 'lan√ßamento', 'clique', 'confira', 'direto',
    'site', 'portfolio', 'fale conosco', 'reserva', 'servi√ßos',
    'parcerias', 'atendimento', 'comprar', 'visite', 'bio atualizada'
]
# Palavras-chave para classificar o tipo de perfil
PALAVRAS_CHAVE_EMPRESA = [
    'sal√£o', 'beleza', 'est√©tica', 'barbearia', 'loja', 'restaurante', 'delivery',
    'oficial', 'store', 'shop', 'boutique', 'studio', 'cl√≠nica', 'consult√≥rio',
    'ag√™ncia', 'servi√ßos', 'encomendas', 'pedidos', 'agendamento', 'or√ßamento',
    'atacado', 'varejo', 'im√≥veis', 'advocacia', 'contabilidade',
    'empresa', 'corporativo', 'neg√≥cios', 'ecommerce', 'marketplace',
    'ind√∫stria', 'f√°brica', 'representa√ß√µes', 'franquia', 'distribuidora',
    'importadora', 'exportadora', 'assist√™ncia t√©cnica', 'manuten√ß√£o', 'oficina',
    'consultoria', 'academia', 'escola', 'educa√ß√£o', 'eventos', 'buffet'
]
PALAVRAS_CHAVE_PESSOA = [
    'blogueira', 'blogger', 'influencer', 'criador de conte√∫do', 'atleta',
    'artista', 'pessoal', 'public figure', 'figura p√∫blica',
    'digital creator', 'modelo', 'creator', 'apresentador', 'ator', 'atriz',
    'm√∫sico', 'cantor', 'cantora', 'youtuber', 'tiktoker', 'streamer',
    'comunicador', 'escritor', 'fot√≥grafo', 'coach', 'mentor',
    'profissional liberal', 'aut√¥nomo', 'portf√≥lio', 'vida real', 'di√°rio',
    'minha vida', 'reflex√µes', 'bio pessoal', 'sobre mim'
]
# Listas para an√°lise de localiza√ß√£o
CAPITAIS_E_CIDADES_IMPORTANTES = [
    # Capitais e principais cidades do Brasil (continua a lista anterior‚Ä¶)
    'palmas', 'goi√¢nia', 'brasilia', 's√£o paulo', 'rio de janeiro', 'belo horizonte',
    'salvador', 'fortaleza', 'recife', 'curitiba', 'porto alegre', 'manaus', 'bel√©m',
    'gurupi', 'aragua√≠na', 'porto nacional', 'para√≠so do tocantins',
    'campinas', 'ribeir√£o preto', 'santos', 's√£o jos√© dos campos', 's√£o lu√≠s',
    'teresina', 'macei√≥', 'jo√£o pessoa', 'natal', 'vit√≥ria', 'cuiab√°', 'campo grande',
    'florian√≥polis', 'joinville', 'londrina', 'maring√°', 'uberl√¢ndia', 'feira de santana',
    'serra', 'jundia√≠', 'anapolis', 'itabuna', 'barueri', 'caruaru', 'ilh√©us',
    'blumenau', 'niter√≥i', 'duque de caxias', 'nova igua√ßu', 'osasco', 'diadema',
    # Todos os munic√≠pios do Tocantins
    'abreu√¢ndia', 'aguiarn√≥polis', 'alian√ßa do tocantins', 'almas', 'alvorada',
    'anan√°s', 'angico', 'aparecida do rio negro', 'aragominas', 'araguacema',
    'aragua√ßu', 'aragua√≠na', 'araguan√£', 'araguatins', 'arapoeima', 'arraias',
    'augustin√≥polis', 'aurora do tocantins', 'axix√° do tocantins', 'baba√ßul√¢ndia',
    'bandeirantes do tocantins', 'barra do ouro', 'barrol√¢ndia', 'bernardo say√£o',
    'bom jesus do tocantins', 'brasil√¢ndia do tocantins', 'brejinho de nazar√©',
    'buriti do tocantins', 'cachoeirinha', 'campinas do tocantins',
    'campo lindos', 'cariri do tocantins', 'carmol√¢ndia', 'carrasco bonito',
    'caseara', 'centen√°rio', 'chapada da arei a', 'chapada de natividade',
    'colinas do tocantins', 'colm√©ia', 'combinado', 'concei√ß√£o do tocantins',
    'couto magalh√£es', 'cristal√¢ndia', 'crix√°s do tocantins', 'darcin√≥polis',
    'dian√≥polis', 'divin√≥polis do tocantins', 'dois irm√£os do tocantins',
    'duer√©', 'esperantina', 'fatima', 'figueir√≥polis', 'filad√©lfia',
    'formoso do araguaia', 'fortaleza do taboc√£o', 'goianorte', 'goiatins',
    'guara√≠', 'gurupi', 'ipueiras', 'itacaj√°', 'itaguatins', 'itapiratins',
    'itapor√£ do tocantins', 'ja√∫ do tocantins', 'juarana', 'juarina', 'lagoa da confus√£o',
    'lagoa do tocantins', 'lajeado', 'lavandeira', 'lizarda', 'luzin√≥polis',
    'marian√≥polis', 'mateiros', 'miracema do tocantins', 'miranorte',
    'monte do carmo', 'monte santo do tocantins', 'muricil√¢ndia', 'natividade',
    'nazar√©', 'nova olinda', 'nova rosal√¢ndia', 'novo acredit√£o', 'novo alegre',
    'novo jardim', 'oliveira de fatima', 'palmas', 'palmeirante', 'palmeiras do tocantins',
    'palmeiropolis', 'para√≠so do tocantins', 'paran√£', 'pau d‚Äôarco', 'peixe',
    'pequizeiro', 'pindorama do tocantins', 'piraqu√™', 'pium', 'ponte alta do bom jesus',
    'ponte alta do tocantins', 'porto alegre do tocantins', 'porto nacional',
    'praia norte', 'presidente kennedy', 'pugmil', 'recursol√¢ndia', 'riachinho',
    'rio da concei√ß√£o', 'rio dos bois', 'rio sono', 'sam p√≥io', 'sampaio',
    'sandol√¢ndia', 'santa f√© do araguaia', 'santa maria do tocantins',
    'santa rita do tocantins', 'santa rosa do tocantins', 'silvan√≥polis',
    's√≠tio novo do tocantins', 'sucupira', 'taguatinga', 'taipas do tocantins',
    'talism√£', 'tocant√≠nia', 'tocantin√≥polis', 'tupirama', 'tupiratins',
    'wagner', 'wanderl√¢ndia', 'xambio√°'
]
ESTADOS = {
    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amap√°', 'AM': 'Amazonas', 'BA': 'Bahia', 'CE': 'Cear√°',
    'DF': 'Distrito Federal', 'ES': 'Esp√≠rito Santo', 'GO': 'Goi√°s', 'MA': 'Maranh√£o', 'MT': 'Mato Grosso',
    'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais', 'PA': 'Par√°', 'PB': 'Para√≠ba', 'PR': 'Paran√°',
    'PE': 'Pernambuco', 'PI': 'Piau√≠', 'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte',
    'RS': 'Rio Grande do Sul', 'RO': 'Rond√¥nia', 'RR': 'Roraima', 'SC': 'Santa Catarina',
    'SP': 'S√£o Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'
}
CIDADES_POR_ESTADO = { 'palmas': 'TO', 'gurupi': 'TO', 'aragua√≠na': 'TO', 'porto nacional': 'TO', 'para√≠so do tocantins': 'TO', 'goi√¢nia': 'GO', 'brasilia': 'DF' }

# Listas para an√°lise demogr√°fica
NOMES_MASCULINOS = [
    'jos√©', 'jo√£o', 'ant√¥nio', 'francisco', 'carlos', 'paulo', 'pedro',
    'lucas', 'luiz', 'marcos', 'lu√≠s', 'gabriel', 'rafael', 'daniel',
    'marcelo', 'bruno', 'eduardo', 'felipe', 'andr√©', 'fernando',
    'rodrigo', 'gustavo', 'guilherme', 'ricardo', 'tiago', 's√©rgio',
    'vin√≠cius',
    'henrique', 'leonardo', 'alexandre', 'thiago', 'henri', 'jorge',
    'fernando', 'mateus', 'vincent', 'isaac', 'samuel', 'arthur',
    'heitor', 'nicolas', 'ramon', 'alex', 'luan', 'caio', 'igor',
    'rafael', 'davi', 'benjamin', 'enrique', 'isaque', 'gabriel',
    'rafinha', 'marcos vin√≠cius', 'marcos paulo', 'michael'
]
NOMES_FEMININOS = [
    'maria', 'ana', 'francisca', 'ant√¥nia', 'adriana', 'juliana', 'm√°rcia',
    'fernanda', 'patr√≠cia', 'aline', 'sandra', 'camila', 'amanda', 'bruna',
    'j√©ssica', 'let√≠cia', 'j√∫lia', 'luciana', 'vanessa', 'mariana', 'gabriela',
    'vera', 'vit√≥ria', 'larissa', 'cl√°udia', 'beatriz',
    # Acr√©scimos:
    'rafaela', 'priscila', 'carla', 'daniela', 'aline', 'isabela',
    'thais', 'paula', 'renata', 'michele', 'juliana', 'nat√°lia',
    'karen', 'aline', 'aline', 'aline', 'aline', 
    'catarina', 'fl√°via', 'rosana', 'eliana', 'tatiane', 'm√¥nica',
    'elisa', 'eymara', 'julia', 'helo√≠sa', 'mara', 'diana', 'evelyn',
    'sabrina', 'marina', 'ros√¢ngela', 'roseli', 'silvana', 'elizabete'
]
INTERESSES_E_PROFISSOES = {
    "Sa√∫de & Bem-estar": [
        'm√©dica', 'm√©dico', 'nutri', 'nutricionista', 'psic√≥loga', 'psic√≥logo',
        'dentista', 'fisio', 'fisioterapeuta', 'enfermeira', 'enfermeiro',
        'terapeuta', 'fonoaudi√≥loga', 'fonoaudi√≥logo', 'bem-estar', 'sa√∫de',
        'massoterapeuta', 'acupunturista', 'osteopata'
    ],
    "Direito": [
        'advogada', 'advogado', 'advocacia', 'direito', 'oab',
        'jur√≠dico', 'defensora p√∫blica', 'promotor', 'escriv√£'
    ],
    "Beleza & Est√©tica": [
        'beleza', 'est√©tica', 'maquiadora', 'makeup', 'cabelo', 'nail',
        'designer de sobrancelhas', 'micropigmentadora', 'esteticista',
        'manicure', 'pedicure', 'cosmet√≥loga', 'lash designer'
    ],
    "Fitness & Esportes": [
        'fitness', 'fit', 'muscula√ß√£o', 'crossfit', 'personal trainer',
        'educador f√≠sico', 'atleta', 'treinador', 'corredor', 'ciclista',
        'yoga', 'pilates', 'dan√ßarina', 'dan√ßarino', 'lutador'
    ],
    "Marketing & Digital": [
        'marketing', 'mkt', 'social media', 'conte√∫do digital', 'influencer',
        'publicidade', 'copywriter', 'gestora de tr√°fego', 'freelancer',
        'consultora digital', 'criador de conte√∫do', 'branding', 'produtor digital'
    ],
    "Moda": [
        'moda', 'fashion', 'look', 'estilo', 'consultora de imagem',
        'modelo', 'influencer de moda', 'stylist', 'personal stylist',
        'tend√™ncia', 'produ√ß√£o de moda'
    ],
    "Educa√ß√£o": [
        'professora', 'professor', 'educadora', 'pedagoga', 'licenciatura',
        'ensino', 'psicopedagoga', 'orientadora educacional', 'revisora',
        'alfabetiza√ß√£o', 'tutora', 'mestre', 'doutoranda'
    ],
    "Tecnologia": [
        'programador', 'desenvolvedor', 'dev', 'analista de sistemas',
        'engenheiro de software', 'TI', 'dados', 'machine learning',
        'ux/ui', 'designer gr√°fico', 'frontend', 'backend', 'fullstack'
    ],
    "Neg√≥cios & Finan√ßas": [
        'empreendedora', 'empreendedor', 'consultora', 'coach',
        'mentor', 'neg√≥cios', 'investimentos', 'trader',
        'economista', 'administradora', 'finan√ßas pessoais'
    ],
    "Artes & Criatividade": [
        'artista', 'artes√£', 'pintora', 'ilustradora', 'fot√≥grafa',
        'cinegrafista', 'produtora cultural', 'criativa', 'designer',
        'arquitetura', 'decora√ß√£o', 'm√∫sica', 'cantora', 'escritora'
    ]
}
PALAVRAS_CHAVE_ESTUDANTE = {
    "TERMOS_GENERICOS": [
        'estudante', 'aluno', 'aluna', 'acad√™mico', 'acad√™mica',
        'universit√°rio', 'universit√°ria', 'cursando', 'formando', 'formanda',
        'calouro', 'caloura', 'graduando', 'graduanda', 'p√≥s-graduando',
        'mestrando', 'doutorando', 'residente'
    ],
    "INSTITUICOES": [
        'faculdade', 'universidade', 'escola', 'col√©gio', 'instituto',
        'uf', 'ue', 'puc', 'fgv', 'uft', 'unitins', 'ifto',
        'unesp', 'usp', 'ufrj', 'ufmg', 'ufba', 'unb', 'unicamp',
        'ufsc', 'ufpe', 'ufpr', 'ufes', 'ufpa', 'unifesp', 'ueg',
        'ufc', 'if', 'ifsp', 'ifrn', 'ifba', 'ifce', 'ifpb'
    ],
    "CURSOS": [
        'direito', 'medicina', 'engenharia', 'engenharia civil',
        'engenharia el√©trica', 'engenharia mec√¢nica', 'administra√ß√£o', 'adm',
        'jornalismo', 'publicidade', 'arquitetura', 'odonto', 'odontologia',
        'psicologia', 'enfermagem', 'biomedicina', 'nutri√ß√£o', 'farm√°cia',
        'fisioterapia', 'ci√™ncias cont√°beis', 'contabilidade', 'educa√ß√£o f√≠sica',
        'pedagogia', 'letras', 'hist√≥ria', 'geografia', 'design', 'computa√ß√£o',
        'sistemas de informa√ß√£o', 'ci√™ncia da computa√ß√£o', 'an√°lise e desenvolvimento de sistemas'
    ],
    "PADROES_REGEX": [
        r'\d¬∫\s?per√≠odo', r'\d\s?semestre', r'turma\s?\d+', r'\d¬∫\s?ano',
        r'classe\s?\d+', r'm√≥dulo\s?\d+', r'est√°gio\s?(supervisionado|obrigat√≥rio)?',
        r'grupo\s?\d+', r'monografia', r'tcc', r'banca\s?final'
    ]
}
# =======================================================================================
# --- FUN√á√ïES DE AN√ÅLISE ---

def converter_para_numero(valor):
    if isinstance(valor, (int, float)): return int(valor)
    if not isinstance(valor, str): return 0
    valor = valor.lower().strip().replace(',', '.')
    if 'k' in valor: return int(float(valor.replace('k', '')) * 1000)
    if 'm' in valor: return int(float(valor.replace('m', '')) * 1000000)
    valor_numerico = re.sub(r'[^0-9]', '', valor)
    return int(valor_numerico) if valor_numerico else 0

def extrair_localizacao(row):
    texto_busca = f"{str(row.get('bio', ''))} {str(row.get('nome_completo', ''))} {str(row.get('endereco', ''))}".lower()
    cidade_encontrada, estado_encontrado = "", ""
    for sigla in ESTADOS:
        if re.search(r'\b' + sigla.lower() + r'\b', texto_busca):
            estado_encontrado = sigla
            break
    for cidade in CAPITAIS_E_CIDADES_IMPORTANTES:
        if cidade in texto_busca:
            cidade_encontrada = cidade.title()
            if not estado_encontrado and cidade in CIDADES_POR_ESTADO:
                estado_encontrado = CIDADES_POR_ESTADO[cidade]
            break
    return cidade_encontrada, estado_encontrado

def extrair_caracteristicas_demograficas(row):
    texto_busca = f"{str(row.get('bio', '')).lower()} {str(row.get('username', '')).lower()}"
    nome_completo = str(row.get('nome_completo', '')).lower()
    idade_aprox, genero_inferido = None, "Indefinido"
    try: # Infer√™ncia de Idade
        match_anos = re.search(r'\b(1[8-9]|[2-9]\d)\s?anos\b', texto_busca)
        if match_anos: idade_aprox = int(match_anos.group(1))
        else:
            match_ano4 = re.search(r'\b(19[5-9]\d|200[0-5])\b', texto_busca)
            if match_ano4: idade_aprox = datetime.now().year - int(match_ano4.group(1))
            else:
                match_ano2 = re.search(r'[\'|\/](\d{2})\b', texto_busca)
                if match_ano2:
                    ano = int(match_ano2.group(1))
                    ano_nascimento = 1900 + ano if ano > (datetime.now().year - 2000) else 2000 + ano
                    idade_aprox = datetime.now().year - ano_nascimento
    except: pass
    try: # Infer√™ncia de G√™nero
        primeiro_nome = nome_completo.split(' ')[0]
        if primeiro_nome in NOMES_FEMININOS: genero_inferido = "Feminino"
        elif primeiro_nome in NOMES_MASCULINOS: genero_inferido = "Masculino"
    except: pass
    return idade_aprox, genero_inferido

def identificar_estudante(row):
    texto_busca = f"{str(row.get('bio', ''))} {str(row.get('categoria', ''))}".lower()
    eh_estudante, detalhe_estudo = "N√£o", ""
    if not texto_busca.strip(): return eh_estudante, detalhe_estudo
    for padrao in PALAVRAS_CHAVE_ESTUDANTE["PADROES_REGEX"]:
        match = re.search(padrao, texto_busca)
        if match: return "Sim", match.group(0)
    todas_palavras = PALAVRAS_CHAVE_ESTUDANTE["TERMOS_GENERICOS"] + PALAVRAS_CHAVE_ESTUDANTE["INSTITUICOES"] + PALAVRAS_CHAVE_ESTUDANTE["CURSOS"]
    palavras_encontradas = [palavra.title() for palavra in todas_palavras if re.search(r'\b' + palavra + r'\b', texto_busca)]
    if palavras_encontradas:
        eh_estudante = "Sim"
        detalhe_estudo = ", ".join(palavras_encontradas)
    return eh_estudante, detalhe_estudo

def executar_analise_completa(df):
    """Aplica todas as fun√ß√µes de an√°lise e classifica√ß√£o ao DataFrame."""
    logging.info("Iniciando pipeline de an√°lise completa...")

    # Garante que colunas essenciais existam e preenche valores nulos
    for col in ['n_seguidores', 'n_seguindo', 'email', 'telefone', 'link_externo', 'bio', 'categoria', 'nome_completo', 'username', 'endereco']:
        if col not in df.columns: df[col] = ''
    df.fillna({'bio': '', 'categoria': '', 'nome_completo': '', 'endereco': ''}, inplace=True)

    # --- ETAPA 1: An√°lise B√°sica ---
    logging.info("ETAPA 1/5: Realizando an√°lise b√°sica (influ√™ncia, contato, etc.)...")
    df['n_seguidores_num'] = df['n_seguidores'].apply(converter_para_numero)
    df['n_seguindo_num'] = df['n_seguindo'].apply(converter_para_numero)
    df['nivel_influencia'] = df['n_seguidores_num'].apply(lambda x: 'Iniciante (< 1k)' if x < 1000 else 'Nano-influenciador (1k - 10k)' if x < 10000 else 'Micro-influenciador (10k - 100k)' if x < 100000 else 'M√©dio Porte (100k - 1M)' if x < 1000000 else 'Macro/Mega-influenciador (> 1M)')
    df['ratio_seguidores_seguindo'] = round(df['n_seguidores_num'] / df['n_seguindo_num'].apply(lambda x: max(1, x)), 2)
    df['potencial_contato'] = df.apply(lambda row: 'Sim' if pd.notna(row['email']) and row['email'] or pd.notna(row['telefone']) and row['telefone'] else 'N√£o', axis=1)
    df['possui_link_externo'] = df['link_externo'].apply(lambda x: 'Sim' if pd.notna(x) and x else 'N√£o')
    df['palavras_chave_bio'] = df['bio'].apply(lambda bio: ", ".join([p for p in PALAVRAS_CHAVE_BIO_GERAL if isinstance(bio, str) and p in bio.lower()]))

    # --- ETAPA 2: Classifica√ß√£o de Tipo de Perfil ---
    logging.info("ETAPA 2/5: Classificando tipo de perfil (Empresa vs. Pessoa)...")
    df['tipo_perfil'] = df.apply(lambda row: "Empresa / Com√©rcio" if (sum(p in str(row.get('categoria','')).lower() for p in PALAVRAS_CHAVE_EMPRESA)*5 + sum(p in f"{str(row.get('bio',''))} {str(row.get('nome_completo',''))}".lower() for p in PALAVRAS_CHAVE_EMPRESA)*3 + (2 if row.get('potencial_contato') == 'Sim' else 0) + (1 if row.get('possui_link_externo') == 'Sim' else 0) - (2 if sum(p in str(row.get('categoria','')).lower() for p in PALAVRAS_CHAVE_PESSOA) else 0)) >= 4 else "Pessoa / Criador", axis=1)

    # --- ETAPA 3: Extra√ß√£o de Localiza√ß√£o ---
    logging.info("ETAPA 3/5: Extraindo informa√ß√µes de localiza√ß√£o (cidade/estado)...")
    df[['cidade', 'estado']] = df.apply(extrair_localizacao, axis=1, result_type='expand')

    # --- ETAPA 4: An√°lise Demogr√°fica ---
    logging.info("ETAPA 4/5: Inferindo idade e g√™nero...")
    df[['idade_aprox', 'genero_inferido']] = df.apply(extrair_caracteristicas_demograficas, axis=1, result_type='expand')
    
    # --- ETAPA 5: Identifica√ß√£o de Estudantes ---
    logging.info("ETAPA 5/5: Identificando prov√°veis estudantes...")
    df[['eh_estudante', 'detalhe_estudo']] = df.apply(identificar_estudante, axis=1, result_type='expand')

    df.drop(columns=['n_seguidores_num', 'n_seguindo_num'], inplace=True, errors='ignore')
    logging.info("‚úÖ Pipeline de an√°lise conclu√≠do!")
    return df

# --- FLUXO PRINCIPAL ---
if __name__ == "__main__":
    if not os.path.exists(ARQUIVO_ENTRADA):
        logging.error(f"‚ùå O arquivo de entrada '{ARQUIVO_ENTRADA}' n√£o foi encontrado!")
        exit()
    try:
        logging.info(f"Lendo o arquivo de dados: {ARQUIVO_ENTRADA}")
        dataframe_original = pd.read_csv(ARQUIVO_ENTRADA)
        dataframe_analisado = executar_analise_completa(dataframe_original.copy())
        
        # Reorganiza as colunas para melhor visualiza√ß√£o
        colunas_principais = ['username', 'nome_completo', 'tipo_perfil', 'cidade', 'estado', 'genero_inferido', 'idade_aprox', 'nivel_influencia', 'n_seguidores', 'potencial_contato', 'eh_estudante', 'detalhe_estudo']
        outras_colunas = [col for col in dataframe_analisado.columns if col not in colunas_principais]
        dataframe_final = dataframe_analisado[colunas_principais + outras_colunas]
        
        dataframe_final.to_csv(ARQUIVO_SAIDA, index=False, encoding='utf-8')
        
        logging.info("="*60)
        logging.info(f"üéâ SUCESSO! O arquivo com a an√°lise COMPLETA foi salvo em:")
        logging.info(f"   üëâ {ARQUIVO_SAIDA}")
        logging.info("="*60)

        logging.info("RESUMO DA AN√ÅLISE COMPLETA:")
        print("\n--- Classifica√ß√£o de Tipo de Perfil ---")
        print(dataframe_final['tipo_perfil'].value_counts())
        print("\n--- Resumo de Localiza√ß√µes (Estados) ---")
        print(dataframe_final['estado'].value_counts().head(5))
        print("\n--- Resumo de G√™neros Inferidos ---")
        print(dataframe_final['genero_inferido'].value_counts())
        print("\n--- Resumo da Identifica√ß√£o de Estudantes ---")
        print(dataframe_final['eh_estudante'].value_counts())

    except Exception as e:
        logging.critical(f"‚ùå Um erro inesperado ocorreu durante a an√°lise: {e}")