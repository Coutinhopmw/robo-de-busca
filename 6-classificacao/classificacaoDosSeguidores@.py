import pandas as pd
import logging
import os
import re
from datetime import datetime

# --- CONFIGURA√á√ïES GERAIS ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# Caminho absoluto do diret√≥rio do script
DIR_SCRIPT = os.path.dirname(os.path.abspath(__file__))

# Nome do arquivo CSV de entrada (gerado pelo script de tratamento de dados avan√ßados)
ARQUIVO_ENTRADA = os.path.join(DIR_SCRIPT, "..", "5-dadosTratados", "dados_tratados_dados_avancados_seguidores_enriquecido_bjjtocantins.csv")

# ======================= CONFIGURA√á√ïES PARA AN√ÅLISE E SEGMENTA√á√ÉO =======================
# 1. Defina as colunas que voc√™ quer usar para criar as pastas e segmentar os arquivos CSV.
COLUNAS_PARA_SEGMENTAR = [
    'tipo_perfil',
    'estado',
    'cidade',
    'eh_estudante',
    'curso_inferido',
    'area_profissional_inferida',
    'genero_inferido',
    'nivel_influencia',
    'profissao',
    'instituicao_ensino'
]

# 2. (Opcional) Personalize as listas de palavras-chave para refinar a precis√£o da an√°lise.
# Mantive as listas expandidas que voc√™ criou, pois s√£o excelentes.
PALAVRAS_CHAVE_EMPRESA = [
    'sal√£o', 'beleza', 'est√©tica', 'barbearia', 'loja', 'restaurante', 'delivery', 'oficial', 'store', 
    'shop', 'boutique', 'studio', 'cl√≠nica', 'consult√≥rio', 'ag√™ncia', 'servi√ßos', 'encomendas', 
    'pedidos', 'agendamento', 'or√ßamento', 'atacado', 'varejo', 'im√≥veis', 'advocacia', 'contabilidade',
    'empresa', 'corporativo', 'neg√≥cios', 'ecommerce', 'marketplace', 'consultoria', 'academia', 'escola'
]
PALAVRAS_CHAVE_PESSOA = [
    'blogueira', 'blogger', 'influencer', 'criador de conte√∫do', 'atleta', 'artista', 'pessoal', 
    'public figure', 'figura p√∫blica', 'digital creator', 'modelo', 'creator', 'youtuber', 'tiktoker'
]
CAPITAIS_E_CIDADES_IMPORTANTES = ['palmas', 'goi√¢nia', 'brasilia', 's√£o paulo', 'rio de janeiro', 'belo horizonte', 'salvador', 'fortaleza', 'recife', 'curitiba', 'porto alegre', 'manaus', 'bel√©m', 'gurupi', 'aragua√≠na', 'porto nacional', 'para√≠so do tocantins']
ESTADOS = {'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amap√°', 'AM': 'Amazonas', 'BA': 'Bahia', 'CE': 'Cear√°', 'DF': 'Distrito Federal', 'ES': 'Esp√≠rito Santo', 'GO': 'Goi√°s', 'MA': 'Maranh√£o', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais', 'PA': 'Par√°', 'PB': 'Para√≠ba', 'PR': 'Paran√°', 'PE': 'Pernambuco', 'PI': 'Piau√≠', 'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul', 'RO': 'Rond√¥nia', 'RR': 'Roraima', 'SC': 'Santa Catarina', 'SP': 'S√£o Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'}
CIDADES_POR_ESTADO = { 'palmas': 'TO', 'gurupi': 'TO', 'aragua√≠na': 'TO', 'porto nacional': 'TO', 'para√≠so do tocantins': 'TO', 'goi√¢nia': 'GO', 'brasilia': 'DF' }
NOMES_MASCULINOS = ['jos√©', 'jo√£o', 'ant√¥nio', 'francisco', 'carlos', 'paulo', 'pedro', 'lucas', 'luiz', 'marcos', 'lu√≠s', 'gabriel', 'rafael', 'daniel', 'marcelo', 'bruno', 'eduardo', 'felipe', 'andr√©', 'fernando', 'rodrigo', 'gustavo', 'guilherme', 'ricardo', 'tiago', 's√©rgio', 'vin√≠cius']
NOMES_FEMININOS = ['maria', 'ana', 'francisca', 'ant√¥nia', 'adriana', 'juliana', 'm√°rcia', 'fernanda', 'patr√≠cia', 'aline', 'sandra', 'camila', 'amanda', 'bruna', 'j√©ssica', 'let√≠cia', 'j√∫lia', 'luciana', 'vanessa', 'mariana', 'gabriela', 'vera', 'vit√≥ria', 'larissa', 'cl√°udia', 'beatriz']
PALAVRAS_CHAVE_ESTUDANTE = {"TERMOS_GENERICOS": ["estudante", "aluno", "aluna", "acad√™mico", "cursando", "formando"], "INSTITUICOES": ["faculdade", "universidade", "escola", "instituto", "uf", "ue", "puc", "uft", "unitins", "ifto"], "CURSOS": ["direito", "medicina", "engenharia", "administra√ß√£o", "adm", "odontologia", "psicologia", "arquitetura", "contabilidade", "jornalismo", "marketing", "ti", "computa√ß√£o", "enfermagem", "farm√°cia", "fisioterapia", "nutri√ß√£o", "pedagogia", "veterin√°ria"], "PADROES_REGEX": [r"\d¬∫\s?per√≠odo", r"\d\s?semestre", r"turma\s?\d+"]}
PALAVRAS_CHAVE_PROFISSAO = {"SAUDE": ["m√©dico", "medica", "doutor", "doutora", "enfermeiro", "enfermeira", "fisioterapeuta", "nutricionista", "psic√≥logo", "psic√≥loga", "dentista", "farmac√™utico", "farmac√™utica", "veterin√°rio", "veterin√°ria"], "DIREITO": ["advogado", "advogada", "jur√≠dico", "juiz", "ju√≠za", "promotor", "promotora"], "ENGENHARIA": ["engenheiro", "engenheira", "arquiteto", "arquiteta"], "TI": ["desenvolvedor", "programador", "analista de sistemas", "especialista em ti", "cientista de dados"], "EDUCACAO": ["professor", "professora", "pedagogo", "pedagoga"], "NEGOCIOS": ["administrador", "administradora", "contador", "contadora", "empreendedor", "empres√°rio", "empres√°ria", "consultor", "consultora", "vendedor", "vendedora", "gerente"], "OUTROS": ["jornalista", "designer", "artista", "atleta", "chef", "cozinheiro", "cozinheira", "fot√≥grafo", "fot√≥grafa", "influenciador", "influenciadora"]}
# =======================================================================================


# --- FUN√á√ïES ---

def converter_para_numero(valor):
    if pd.isna(valor): return 0
    if isinstance(valor, (int, float)): return int(valor)
    if not isinstance(valor, str): return 0
    valor = valor.lower().strip().replace(',', '.')
    if 'k' in valor: return int(float(valor.replace('k', '')) * 1000)
    if 'm' in valor: return int(float(valor.replace('m', '')) * 1000000)
    return int(re.sub(r'\D', '', valor)) if re.sub(r'\D', '', valor) else 0

def analisar_e_classificar(df):
    """Aplica o pipeline completo de an√°lise e classifica√ß√£o ao DataFrame."""
    logging.info("Iniciando pipeline de an√°lise e classifica√ß√£o...")
    
    # Sanitiza√ß√£o b√°sica
    df.drop_duplicates(subset=['username'], keep='first', inplace=True)
    for col in ['bio', 'categoria', 'nome_completo', 'endereco']:
        if col in df.columns: df[col] = df[col].fillna('')

    # Aplica an√°lises de influ√™ncia apenas se as colunas existirem
    if 'n_seguidores' in df.columns:
        df['n_seguidores_num'] = df['n_seguidores'].apply(converter_para_numero)
        df['nivel_influencia'] = df['n_seguidores_num'].apply(lambda x: 'Iniciante' if x < 1000 else 'Nano' if x < 10000 else 'Micro' if x < 100000 else 'M√©dio' if x < 1000000 else 'Macro/Mega')
    if 'n_seguindo' in df.columns:
        df['n_seguindo_num'] = df['n_seguindo'].apply(converter_para_numero)
    
    def extrair_local(row):
        texto = f"{row.get('bio', '')} {row.get('nome_completo', '')}".lower()
        cidade, estado = "", ""
        for sigla in ESTADOS:
            if re.search(r'\b' + sigla.lower() + r'\b', texto): estado = sigla; break
        for cid in CAPITAIS_E_CIDADES_IMPORTANTES:
            if cid in texto:
                cidade = cid.title()
                if not estado and cid in CIDADES_POR_ESTADO: estado = CIDADES_POR_ESTADO[cid]
                break
        return cidade, estado
    df[['cidade', 'estado']] = df.apply(extrair_local, axis=1, result_type='expand')



    """Aplica o pipeline completo de an√°lise e classifica√ß√£o ao DataFrame."""
    logging.info("Iniciando pipeline de an√°lise e classifica√ß√£o...")
    
    # Sanitiza√ß√£o b√°sica
    df.drop_duplicates(subset=['username'], keep='first', inplace=True)
    for col in ['bio', 'categoria', 'nome_completo', 'endereco']:
        if col in df.columns: df[col] = df[col].fillna('')

    # Aplica an√°lises de influ√™ncia apenas se as colunas existirem
    if 'n_seguidores' in df.columns:
        df['n_seguidores_num'] = df['n_seguidores'].apply(converter_para_numero)
        df['nivel_influencia'] = df['n_seguidores_num'].apply(lambda x: 'Iniciante' if x < 1000 else 'Nano' if x < 10000 else 'Micro' if x < 100000 else 'M√©dio' if x < 1000000 else 'Macro/Mega')
    if 'n_seguindo' in df.columns:
        df['n_seguindo_num'] = df['n_seguindo'].apply(converter_para_numero)

    def extrair_local(row):
        texto = f"{row.get('bio', '')} {row.get('nome_completo', '')}".lower()
        cidade, estado = "", ""
        for sigla in ESTADOS:
            if re.search(r'\\b' + sigla.lower() + r'\\b', texto): estado = sigla; break
        for cid in CAPITAIS_E_CIDADES_IMPORTANTES:
            if cid in texto:
                cidade = cid.title()
                if not estado and cid in CIDADES_POR_ESTADO: estado = CIDADES_POR_ESTADO[cid]
                break
        return cidade, estado
    df[['cidade', 'estado']] = df.apply(extrair_local, axis=1, result_type='expand')

    def classificar_tipo(row):
        score = 0
        texto = f"{row.get('categoria', '')} {row.get('bio', '')} {row.get('nome_completo', '')}".lower()
        if any(p in texto for p in PALAVRAS_CHAVE_EMPRESA): score += 1
        if any(p in texto for p in PALAVRAS_CHAVE_PESSOA): score -= 1
        return "Empresa / Com√©rcio" if score > 0 else "Pessoa / Criador"
    df['tipo_perfil'] = df.apply(classificar_tipo, axis=1)

    def identificar_estudante(row):
        texto = f"{row.get('bio', '')} {row.get('categoria', '')}".lower()
        if any(re.search(p, texto) for p in PALAVRAS_CHAVE_ESTUDANTE["PADROES_REGEX"]): return "Sim"
        if any(re.search(r'\\b' + p + r'\\b', texto) for p in PALAVRAS_CHAVE_ESTUDANTE["TERMOS_GENERICOS"]): return "Sim"
        if any(re.search(r'\\b' + p + r'\\b', texto) for p in PALAVRAS_CHAVE_ESTUDANTE["INSTITUICOES"]): return "Sim"
        if any(re.search(r'\\b' + p + r'\\b', texto) for p in PALAVRAS_CHAVE_ESTUDANTE["CURSOS"]): return "Sim"
        return "N√£o"
    df['eh_estudante'] = df.apply(identificar_estudante, axis=1)
    
    def identificar_curso_e_profissao(row):
        texto = f"{row.get('bio', '')} {row.get('categoria', '')}".lower()
        curso = 'N√£o identificado'
        profissao = 'N√£o identificado'

        # Identificar Curso
        for c in PALAVRAS_CHAVE_ESTUDANTE["CURSOS"]:
            if re.search(r'\b' + c + r'\b', texto):
                curso = c.title()
                break

        # Identificar Profiss√£o
        for area, profissoes in PALAVRAS_CHAVE_PROFISSAO.items():
            for p in profissoes:
                if re.search(r'\b' + p + r'\b', texto):
                    profissao = p.title()
                    break
            if profissao != 'N√£o identificado':
                break
        
        return curso, profissao

    df[['curso_inferido', 'area_profissional_inferida']] = df.apply(identificar_curso_e_profissao, axis=1, result_type='expand')
    

    def inferir_genero(row):
        primeiro_nome = str(row.get('nome_completo', '')).lower().split(' ')[0]
        if primeiro_nome in NOMES_FEMININOS: return "Feminino"
        if primeiro_nome in NOMES_MASCULINOS: return "Masculino"
        return "Indefinido"
    df['genero_inferido'] = df.apply(inferir_genero, axis=1)

    # --- NOVO: Extra√ß√£o de profiss√£o e institui√ß√£o de ensino ---
    # Lista de profiss√µes comuns (pode ser expandida conforme necess√°rio)
    LISTA_PROFISSOES = [
        'advogado', 'advogada', 'm√©dico', 'm√©dica', 'engenheiro', 'engenheira', 'professor', 'professora',
        'arquiteto', 'arquiteta', 'designer', 'contador', 'contadora', 'nutricionista', 'psic√≥logo', 'psic√≥loga',
        'dentista', 'enfermeiro', 'enfermeira', 'fisioterapeuta', 'veterin√°rio', 'veterin√°ria', 'administrador',
        'administradora', 'empres√°rio', 'empres√°ria', 'coach', 'personal trainer', 'fot√≥grafo', 'fot√≥grafa',
        'artista', 'cantor', 'cantora', 'ator', 'atriz', 'jornalista', 'publicit√°rio', 'publicit√°ria', 'analista',
        'programador', 'programadora', 'desenvolvedor', 'desenvolvedora', 'cientista', 'pesquisador', 'pesquisadora',
        'consultor', 'consultora', 'gerente', 'diretor', 'diretora', 'esteticista', 'manicure', 'maquiadora',
        'barbeiro', 'cozinheiro', 'cozinheira', 'chefe', 'chef', 'motorista', 'vendedor', 'vendedora', 'corretor',
        'corretora', 'biom√©dico', 'biom√©dica', 'farmac√™utico', 'farmac√™utica', 'fisiologista', 'coach', 'influencer',
        'blogueiro', 'blogueira', 'youtuber', 'tiktoker', 'criador de conte√∫do', 'criadora de conte√∫do'
    ]
    # Lista de palavras-chave para institui√ß√µes de ensino
    LISTA_INSTITUICOES = [
        'universidade', 'faculdade', 'instituto', 'escola', 'col√©gio', 'uf', 'ue', 'puc', 'uft', 'unitins', 'ifto',
        'unip', 'unopar', 'uninter', 'unicesumar', 'unifeso', 'unifor', 'unb', 'usp', 'unicamp', 'ufrj', 'ufmg', 'ufba',
        'ufpe', 'ufpr', 'ufsc', 'ufes', 'ufpa', 'ufc', 'ufal', 'ufma', 'ufpb', 'ufrn', 'ufrr', 'ufam', 'ufac', 'ufmt',
        'ufms', 'ufpi', 'ufro', 'ufop', 'ufla', 'ufv', 'ufsj', 'ufjf', 'ufabc', 'ufscar', 'ufpel', 'ufsm', 'ufrgs',
        'ufes', 'ufra', 'ufrb', 'ufersa', 'ufvjm', 'ufersa', 'ufca', 'ufape', 'ufersa', 'ufersa', 'if', 'ifsp', 'ifba',
        'ifce', 'ifmg', 'ifpb', 'ifrn', 'ifrs', 'ifsc', 'ifpr', 'ifro', 'ifam', 'ifac', 'ifmt', 'ifms', 'ifpa', 'ifal',
        'ifma', 'ifpi', 'ifto', 'ifap', 'ifrr', 'ifgoiano', 'ifg', 'ifnmg', 'ifes', 'ifes', 'ifb', 'ifc', 'iffar', 'ifrs',
        'ifsp', 'ifbaiano', 'ifba', 'ifce', 'ifmg', 'ifpb', 'ifrn', 'ifrs', 'ifsc', 'ifpr', 'ifro', 'ifam', 'ifac', 'ifmt',
        'ifms', 'ifpa', 'ifal', 'ifma', 'ifpi', 'ifto', 'ifap', 'ifrr', 'ifgoiano', 'ifg', 'ifnmg', 'ifes', 'ifes', 'ifb',
        'ifc', 'iffar', 'ifrs', 'ifsp', 'ifbaiano', 'unitins', 'uft', 'unirg', 'ulbra', 'cat√≥lica', 'mackenzie', 'senai', 'senac'
    ]

    def extrair_profissao(texto):
        texto = texto.lower()
        for prof in LISTA_PROFISSOES:
            if re.search(r'\\b' + re.escape(prof) + r'\\b', texto):
                return prof.title()
        return ''

    def extrair_instituicao(texto):
        texto = texto.lower()
        for inst in LISTA_INSTITUICOES:
            if re.search(r'\\b' + re.escape(inst) + r'\\b', texto):
                return inst.upper()
        return ''

    # Extrai profiss√£o e institui√ß√£o de ensino da bio/categoria
    df['profissao'] = df.apply(lambda row: extrair_profissao(f"{row.get('bio', '')} {row.get('categoria', '')}"), axis=1)
    df['instituicao_ensino'] = df.apply(lambda row: extrair_instituicao(f"{row.get('bio', '')} {row.get('categoria', '')}"), axis=1)

    logging.info("‚úÖ An√°lise conclu√≠da.")
    return df
# --- FLUXO PRINCIPAL ---
if __name__ == "__main__":
    # Ajusta o ARQUIVO_ENTRADA para o caminho correto do arquivo enviado pelo usu√°rio
    ARQUIVO_ENTRADA = "/home/ubuntu/upload/dados_avancados_seguidores_enriquecido_acipparaisocopy.csv"

    if not os.path.exists(ARQUIVO_ENTRADA):
        logging.error(f"‚ùå O arquivo de entrada '{ARQUIVO_ENTRADA}' n√£o foi encontrado!")
        exit()
    try:
        logging.info(f"Lendo o arquivo de dados: {ARQUIVO_ENTRADA}")
        df_original = pd.read_csv(ARQUIVO_ENTRADA)

        # Roda o pipeline completo de an√°lise
        df_analisado = analisar_e_classificar(df_original.copy())


        # Salva o arquivo completo e unificado na mesma pasta do script
        arquivo_completo_saida = os.path.join(DIR_SCRIPT, "analise_completa.csv")
        df_analisado.to_csv(arquivo_completo_saida, index=False, encoding='utf-8')
        logging.info(f"üéâ SUCESSO! O arquivo com a an√°lise COMPLETA foi salvo em: {arquivo_completo_saida}")

        # Salva os arquivos segmentados na mesma pasta do script
        def salvar_segmentos(df, dir_saida, colunas_para_segmentar):
            """
            Salva arquivos CSV segmentados por combina√ß√µes √∫nicas das colunas especificadas.
            """
            for _, grupo in df.groupby(colunas_para_segmentar):
                # Cria um nome de arquivo baseado nos valores das colunas de segmenta√ß√£o
                valores = [str(grupo.iloc[0][col]) if pd.notna(grupo.iloc[0][col]) and str(grupo.iloc[0][col]).strip() != '' else 'indefinido' for col in colunas_para_segmentar]
                nome_arquivo = "segmento_" + "_".join([re.sub(r'\W+', '', v.lower().replace(' ', '_')) for v in valores]) + ".csv"
                caminho_saida = os.path.join(dir_saida, nome_arquivo)
                grupo.to_csv(caminho_saida, index=False, encoding='utf-8')
                logging.info(f"Segmento salvo: {caminho_saida}")

        salvar_segmentos(df_analisado, DIR_SCRIPT, COLUNAS_PARA_SEGMENTAR)

    except Exception as e:
        logging.critical(f"‚ùå Um erro inesperado ocorreu durante a an√°lise: {e}")


