import pandas as pd
import logging
import os
import re
from datetime import datetime

# --- CONFIGURA√á√ïES GERAIS ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# Caminho absoluto do diret√≥rio do script
DIR_SCRIPT = os.path.dirname(os.path.abspath(__file__))

# Nome do arquivo CSV de entrada (gerado pelo script de coleta de dados avan√ßados)
ARQUIVO_ENTRADA = os.path.join(DIR_SCRIPT, "..", "5-dadosTratados", "dados_avancados_curtidas_completo_sebraeto.csv")

# ======================= CONFIGURA√á√ïES PARA AN√ÅLISE E SEGMENTA√á√ÉO =======================
# 1. Defina as colunas que voc√™ quer usar para criar as pastas e segmentar os arquivos CSV.
COLUNAS_PARA_SEGMENTAR = [
    'tipo_perfil',
    'estado',
    'cidade',
    'estudante',
    'genero_inferido',
    'nivel_influencia'
]

# 2. (Opcional) Personalize as listas de palavras-chave para refinar a precis√£o da an√°lise.
# Mantive as listas expandidas que voc√™ criou, pois s√£o excelentes.
PALAVRAS_CHAVE_EMPRESA = [
    'sal√£o', 'beleza', 'est√©tica', 'barbearia', 'loja', 'restaurante', 'delivery', 'oficial', 'store', 
    'shop', 'boutique', 'studio', 'cl√≠nica', 'consult√≥rio', 'ag√™ncia', 'servi√ßos', 'encomendas', 
    'pedidos', 'agendamento', 'or√ßamento', 'atacado', 'varejo', 'im√≥veis', 'advocacia', 'contabilidade',
    'empresa', 'corporativo', 'neg√≥cios', 'ecommerce', 'marketplace', 'consultoria', 'academia', 'escola'
]
PALAVRAS_CHAVE_PESSOA = [
    'blogueira', 'blogger', 'influencer', 'criador de conte√∫do', 'atleta', 'artista', 'pessoal', 
    'public figure', 'figura p√∫blica', 'digital creator', 'modelo', 'creator', 'youtuber', 'tiktoker'
]
CAPITAIS_E_CIDADES_IMPORTANTES = ['palmas', 'goi√¢nia', 'brasilia', 's√£o paulo', 'rio de janeiro', 'belo horizonte', 'salvador', 'fortaleza', 'recife', 'curitiba', 'porto alegre', 'manaus', 'bel√©m', 'gurupi', 'aragua√≠na', 'porto nacional', 'para√≠so do tocantins']
ESTADOS = {'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amap√°', 'AM': 'Amazonas', 'BA': 'Bahia', 'CE': 'Cear√°', 'DF': 'Distrito Federal', 'ES': 'Esp√≠rito Santo', 'GO': 'Goi√°s', 'MA': 'Maranh√£o', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais', 'PA': 'Par√°', 'PB': 'Para√≠ba', 'PR': 'Paran√°', 'PE': 'Pernambuco', 'PI': 'Piau√≠', 'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul', 'RO': 'Rond√¥nia', 'RR': 'Roraima', 'SC': 'Santa Catarina', 'SP': 'S√£o Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'}
CIDADES_POR_ESTADO = { 'palmas': 'TO', 'gurupi': 'TO', 'aragua√≠na': 'TO', 'porto nacional': 'TO', 'para√≠so do tocantins': 'TO', 'goi√¢nia': 'GO', 'brasilia': 'DF' }
NOMES_MASCULINOS = ['jos√©', 'jo√£o', 'ant√¥nio', 'francisco', 'carlos', 'paulo', 'pedro', 'lucas', 'luiz', 'marcos', 'lu√≠s', 'gabriel', 'rafael', 'daniel', 'marcelo', 'bruno', 'eduardo', 'felipe', 'andr√©', 'fernando', 'rodrigo', 'gustavo', 'guilherme', 'ricardo', 'tiago', 's√©rgio', 'vin√≠cius']
NOMES_FEMININOS = ['maria', 'ana', 'francisca', 'ant√¥nia', 'adriana', 'juliana', 'm√°rcia', 'fernanda', 'patr√≠cia', 'aline', 'sandra', 'camila', 'amanda', 'bruna', 'j√©ssica', 'let√≠cia', 'j√∫lia', 'luciana', 'vanessa', 'mariana', 'gabriela', 'vera', 'vit√≥ria', 'larissa', 'cl√°udia', 'beatriz']
PALAVRAS_CHAVE_ESTUDANTE = {"TERMOS_GENERICOS": ['estudante', 'aluno', 'aluna', 'acad√™mico', 'cursando', 'formando'], "INSTITUICOES": ['faculdade', 'universidade', 'escola', 'instituto', 'uf', 'ue', 'puc', 'uft', 'unitins', 'ifto'], "CURSOS": ['direito', 'medicina', 'engenharia', 'administra√ß√£o', 'adm'], "PADROES_REGEX": [r'\d¬∫\s?per√≠odo', r'\d\s?semestre', r'turma\s?\d+']}

# =======================================================================================


# --- FUN√á√ïES ---

def converter_para_numero(valor):
    if pd.isna(valor): return 0
    if isinstance(valor, (int, float)): return int(valor)
    if not isinstance(valor, str): return 0
    valor = valor.lower().strip().replace(',', '.')
    if 'k' in valor: return int(float(valor.replace('k', '')) * 1000)
    if 'm' in valor: return int(float(valor.replace('m', '')) * 1000000)
    return int(re.sub(r'\D', '', valor)) if re.sub(r'\D', '', valor) else 0

def analisar_e_classificar(df):
    """Aplica o pipeline completo de an√°lise e classifica√ß√£o ao DataFrame."""
    logging.info("Iniciando pipeline de an√°lise e classifica√ß√£o...")
    
    # Sanitiza√ß√£o b√°sica
    df.drop_duplicates(subset=['username'], keep='first', inplace=True)
    for col in ['bio', 'categoria', 'nome_completo', 'endereco']:
        if col in df.columns: df[col] = df[col].fillna('')

    # Aplica an√°lises de influ√™ncia apenas se as colunas existirem
    if 'n_seguidores' in df.columns:
        df['n_seguidores_num'] = df['n_seguidores'].apply(converter_para_numero)
        df['nivel_influencia'] = df['n_seguidores_num'].apply(lambda x: 'Iniciante' if x < 1000 else 'Nano' if x < 10000 else 'Micro' if x < 100000 else 'M√©dio' if x < 1000000 else 'Macro/Mega')
    if 'n_seguindo' in df.columns:
        df['n_seguindo_num'] = df['n_seguindo'].apply(converter_para_numero)
    
    def extrair_local(row):
        texto = f"{row.get('bio', '')} {row.get('nome_completo', '')}".lower()
        cidade, estado = "", ""
        for sigla in ESTADOS:
            if re.search(r'\b' + sigla.lower() + r'\b', texto): estado = sigla; break
        for cid in CAPITAIS_E_CIDADES_IMPORTANTES:
            if cid in texto:
                cidade = cid.title()
                if not estado and cid in CIDADES_POR_ESTADO: estado = CIDADES_POR_ESTADO[cid]
                break
        return cidade, estado
    df[['cidade', 'estado']] = df.apply(extrair_local, axis=1, result_type='expand')

    def classificar_tipo(row):
        score = 0
        texto = f"{row.get('categoria', '')} {row.get('bio', '')} {row.get('nome_completo', '')}".lower()
        if any(p in texto for p in PALAVRAS_CHAVE_EMPRESA): score += 1
        if any(p in texto for p in PALAVRAS_CHAVE_PESSOA): score -= 1
        return "Empresa / Com√©rcio" if score > 0 else "Pessoa / Criador"
    df['tipo_perfil'] = df.apply(classificar_tipo, axis=1)

    def identificar_estudante(row):
        texto = f"{row.get('bio', '')} {row.get('categoria', '')}".lower()
        if any(re.search(p, texto) for p in PALAVRAS_CHAVE_ESTUDANTE["PADROES_REGEX"]): return "Sim"
        if any(re.search(r'\b' + p + r'\b', texto) for p in PALAVRAS_CHAVE_ESTUDANTE["TERMOS_GENERICOS"]): return "Sim"
        if any(re.search(r'\b' + p + r'\b', texto) for p in PALAVRAS_CHAVE_ESTUDANTE["INSTITUICOES"]): return "Sim"
        if any(re.search(r'\b' + p + r'\b', texto) for p in PALAVRAS_CHAVE_ESTUDANTE["CURSOS"]): return "Sim"
        return "N√£o"
    df['eh_estudante'] = df.apply(identificar_estudante, axis=1)
    
    def inferir_genero(row):
        primeiro_nome = str(row.get('nome_completo', '')).lower().split(' ')[0]
        if primeiro_nome in NOMES_FEMININOS: return "Feminino"
        if primeiro_nome in NOMES_MASCULINOS: return "Masculino"
        return "Indefinido"
    df['genero_inferido'] = df.apply(inferir_genero, axis=1)

    logging.info("‚úÖ An√°lise conclu√≠da.")
    return df

def salvar_segmentos(df, base_path, colunas_para_segmentar):
    """Salva o DataFrame em m√∫ltiplos arquivos CSV segmentados por colunas espec√≠ficas."""
    logging.info("Iniciando salvamento dos segmentos...")
    for coluna in colunas_para_segmentar:
        if coluna not in df.columns:
            logging.warning(f"Coluna '{coluna}' n√£o encontrada para segmenta√ß√£o. Pulando.")
            continue
        
        # Agrupa o dataframe pelos valores √∫nicos da coluna
        grupos = df.groupby(coluna)
        
        for nome_grupo, df_grupo in grupos:
            if pd.isna(nome_grupo) or not nome_grupo:
                continue # Ignora grupos com nome vazio ou NaN
            
            # Limpa o nome do grupo para criar um nome de arquivo/pasta v√°lido
            nome_limpo = re.sub(r'[^\w\s-]', '', str(nome_grupo)).strip().replace(' ', '_')
            
            # Cria a pasta para a categoria (ex: /Tipo de Perfil/)
            pasta_categoria = os.path.join(base_path, coluna.replace('_', ' ').title())
            os.makedirs(pasta_categoria, exist_ok=True)
            
            # Define o caminho final do arquivo CSV
            caminho_csv = os.path.join(pasta_categoria, f"{nome_limpo}.csv")
            
            logging.info(f"   - Salvando segmento: {caminho_csv} ({len(df_grupo)} registros)")
            df_grupo.to_csv(caminho_csv, index=False, encoding='utf-8')
    logging.info("‚úÖ Salvamento dos segmentos conclu√≠do.")

# --- FLUXO PRINCIPAL ---
if __name__ == "__main__":
    if not os.path.exists(ARQUIVO_ENTRADA):
        logging.error(f"‚ùå O arquivo de entrada '{ARQUIVO_ENTRADA}' n√£o foi encontrado!")
        exit()
    try:
        logging.info(f"Lendo o arquivo de dados: {ARQUIVO_ENTRADA}")
        df_original = pd.read_csv(ARQUIVO_ENTRADA)

        # Roda o pipeline completo de an√°lise
        df_analisado = analisar_e_classificar(df_original.copy())


        # Salva o arquivo completo e unificado na mesma pasta do script
        arquivo_completo_saida = os.path.join(DIR_SCRIPT, "analise_completa.csv")
        df_analisado.to_csv(arquivo_completo_saida, index=False, encoding='utf-8')
        logging.info(f"üéâ SUCESSO! O arquivo com a an√°lise COMPLETA foi salvo em: {arquivo_completo_saida}")

        # Salva os arquivos segmentados na mesma pasta do script
        salvar_segmentos(df_analisado, DIR_SCRIPT, COLUNAS_PARA_SEGMENTAR)

    except Exception as e:
        logging.critical(f"‚ùå Um erro inesperado ocorreu durante a an√°lise: {e}")